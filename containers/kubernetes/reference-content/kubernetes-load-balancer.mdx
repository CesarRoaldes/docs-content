---
meta:
  title: Creating and configuring a Load Balancer for your Kubernetes cluster
  description: This page explains how to create and configure a Load Balancer for your Kubernetes cluster
content:
  h1: Creating and configuring a Load Balancer for your Kubernetes cluster
  paragraph: This page explains how to create and configure a Load Balancer for your Kubernetes cluster
tags: kubernetes loadbalancer load-balancer external ingress service annotations
dates:
  validation: 2023-10-24
  posted: 2023-10-24
categories:
  - kubernetes
---

By default, Kubernetes clusters are not exposed to the internet. This prevents external users from being able to access the application deployed in your cluster. There are a number of different ways to expose your cluster to the internet: one of them is by creating an external Load Balancer for your cluster. In this document, we explain when and why a Load Balancer may be the right solution for exposing your cluster, and explain the basics of how to create and configure a Load Balancer for your cluster.

## Ways to expose a cluster 

In Kubernetes, you generally need to use a [Service](/containers/kubernetes/concepts/#services) to expose an application in your cluster to the internet. A service groups together pods performing the same function (e.g. running the same application) and defines how to access them. 

The most basic type of service is **ClusterIP**, but this only provides internal access, from within the cluster, to the defined pods. The **NodePort** and **LoadBalancer** services both provide external access. **Ingress** (which is not a service but an API object inside a cluster) combined with an explicitly-created **Ingress Controller** is another way to expose the cluster.

See the table below for more information.


| Method            | Description | Suitable for | Limitations |
| ----------------- | ----------- | ------------ | ----------- |
| **Cluster IP Service** | • Provides internal connectivity between cluster components. <br/>• Has a fixed IP address, from which it balances traffic between pods with matching labels. | Internal communication between different components within a cluster | Cannot be used to expose an application inside the cluster to the public internet. |
| **Node Port Service**  | • Exposes a specific port on each node of a cluster. <br/>• Forwards external traffic received on that port to the right pods. | • Exposing single-node, low-traffic clusters to the internet for free <br/>• Testing. | • Not ideal for production or complex clusters <br/> • Single point of failure.<br/> • Not all port numbers can be opened.|
| **Load Balancer Service** | • Creates a single, external Load Balancer with a public IP <br/> • External LB forwards all traffic to the corresponding LoadBalancer service within the cluster <br/> • LoadBalancer service then forwards traffic to the right pods. <br/> • Operates at the L4 level | • Exposing a service in the cluster to the internet. <br/>• Production envs (highly available). <br/>• Dealing with TCP traffic. | • Each service in the cluster needs its own Load Balancer (can become costly) |
| **Ingress** | • A native resource inside the cluster (not a service) <br/>• Ingress Controller receives a single, external public IP, usually in front of a spun-up external HTTP Load Balancer <br/> • Uses a set of rules to forward web traffic (HTTP/S) to the correct service out of multiple services within the cluster. <br/> • Each service then sends the traffic to a suitable pod. <br/> • Operates at the L7 level.| • Clusters with many different services <br/> • Dealing with HTTP/S traffic | • Requires an Ingress Controller (not included by default, must be created). <br/> • Designed for HTTP/S traffic only (more complicated to configure for other protocols). | 


The following documentation may be useful to you when considering how to expose your cluster: 

- [How to expose my application?](https://www.youtube.com/watch?v=V0uKqYXJRF4) **VIDEO**: From 5m47 to 13m43 the different methods to expose a cluster are described and compared.
- [Exposing a service via NodePort](/tutorials/get-started-deploy-kapsule/#exposing-the-service-for-testing-via-nodeport-(optional))
- [NodePort vs LoadBalancer, and how to create a LoadBalancer service](/tutorials/get-started-kubernetes-loadbalancer/)
- [How to deploy an Ingress Controller](/containers/kubernetes/how-to/deploy-ingress-controller/)

## Ingress or LoadBalancer?

When considering whether to expose your application via Ingress (and an Ingress Controller) or a LoadBalancer service, consider the following:

- A Load Balancer on its own may be sufficient if you have one or few services that you want to expose in your cluster. Each service will need its own external Load Balancer and LoadBalancer service.
- A Load Balancer is also most appropriate for dealing with external TCP traffic
- Ingress Controller with an external Load Balancer may be most appropriate if you have multiple services running in your cluster, and you want to direct HTTP traffic from a single external access point, to different services within your cluster, based on a set of rules.

See [how to create an Ingress Controller](TODO) to find out how to easily create an Ingress Controller for your cluster from the Scaleway console. 

Watch our [webinar](https://www.youtube.com/watch?v=V0uKqYXJRF4) for a deeper dive and practical demonstration of how to create an Ingress Controller with a Load Balancer for your cluster (from the 14 minute mark to the 48 minute mark).

Read on to find out how to create a Load Balancer for your cluster without using Ingress.

## Creating a Load Balancer for your cluster: overview

Here is a quick overview of how to create a Load Balancer for your cluster:

- [Create a Scaleway Kubernetes Kapsule cluster](/network/load-balancer/how-to/create-load-balancer) with an application running inside.
- Make sure you have [installed and configured kubectl](https://www.scaleway.com/en/docs/containers/kubernetes/how-to/connect-cluster-kubectl/)
- Create a yaml manifest to describe the LoadBalancer service you want to create
- Deploy the LoadBalancer service based on the manifest, using kubectl. The Cloud Controller Manager (CCM) will spin up the external [Scaleway Load Balancer](https://www.scaleway.com/en/docs/network/load-balancer/quickstart/) with the correct configuration to forward traffic to the LoadBalancer service within your cluster.
- Use [Load Balancer annotations](https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-annotations.md) to edit your yaml manifest as necessary to alter your Load Balancer's configuration, putting any new annotations into effect via kubectl, so the CCM can carry out the modifications as necessary.

<Message type="important">
Load Balancers for Kubernetes clusters should **always** be provisioned via the cluster's Cloud Controller Manager. It is **not** correct procedure to provision the Load Balancer by creating a Scaleway Load Balancer in the console or via the API, and then attempting to use it as your cluster's external Load Balancer. Similarly, you cannot use the Scaleway console or devtools to edit your cluster's Load Balancer after creation, this must be done via the CCM, as detailed in this documentation.
</Message>

## Creating a Load Balancer for your cluster: step by step

<Message type="requirement">
  - You have an account and are logged into the [Scaleway console](https://console.scaleway.com)
  - You have [created a Kubernetes Kapsule cluster](/network/load-balancer/how-to/create-load-balancer)
  - You have [installed and configured kubectl](https://www.scaleway.com/en/docs/containers/kubernetes/how-to/connect-cluster-kubectl/)
  - You have an application running in your cluster. (Find an example webserver application to run [here](https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-examples.md))

</Message>

1. Create a `.yaml` file to hold the manifest for your cluster's Load Balancer. This will describe the resource (Load Balancer) that you want to create. 

        Below, find an example for the content of the yaml manifest. You will need to edit it to your own specifications. 

        ```yaml
        apiVersion: v1
        kind: Service
        metadata:
        name: myloadbalancer
        spec:
        type: LoadBalancer
        ports:
        - port: 8000
            name: http
            targetPort: 8000
        selector:
            app: mydeployment
        ```

        - `apiVersion`: which version of the Kubernetes API to use to create the object
        - `kind`: the kind of object defined in this yaml file. For a Load Balancer, specify a `Service`
        - `metadata`: helps uniquely identify the Service object: give it a `name` (e.g. `myloadbalancer`).
        - `spec`: specifies the Service: 
            - `type`: the type of Service required: a `LoadBalancer` Service. 
            - `ports`: the ports for the Service configuration. You can define many ports if you want, here we specify just one:
            - `port`: the new service port that will be created, for connecting to the application
            - `name`: a name for this port, e.g. `http`
            - `targetPort`: the application port to target with requests coming from the Service 
            - `selector`: links the LoadBalancer Service with a set of Pods in the cluster. Ensure that the `app` specified matches the name of the deployment of your app in the cluster (run `kubectl get all` if necessary to check the name).

        <Message type="tip">
        See [the Kubernetes documentation](/containers/kubernetes/api-cli/exposing-services/#creating-a-load-balancer-service) for another example of a yaml manifest to create a Load Balancer.
        </Message>

2. Use the command `kubectl create -f <name-of-manifest-file>.yaml` to tell the Kubernetes Cloud Controller to create the Load Balancer from the manifest.

3. Run `kubectl get svc` to confirm that the Load Balancer Service has been created, and view its external IP. You can also check the [Load Balancer](https://console.scaleway.com/load-balancer/) section of the Scaleway console, where your Kuberenetes cluster's Load Balancer now appears. Note that you should **not** attempt to edit or delete the Load Balancer via the console, only via the manifest file and kubectl.

### Specifying an IP address for your Load Balancer

By default, when you create a Load Balancer for your cluster, it will be assigned a public IP address at random. When you delete the Load Balancer, the IP address will also be deleted, and cannot be retrieved to transfer to another Load Balancer service in your cluster. 

However, it is possible to use [flexible IP addresses](/network/load-balancer/concepts/#flexible-ip-address) with your cluster's Load Balancer, to give you more control over the IPs being used. Flexible IP addresses can be kept in your account even if/when their associated Load Balancer is deleted. They can then be assigned to a new Load Balancer in the future.

To specify that an existing flexible IP address that you hold in your account should be used when creating your Load Balancer, add the `loadBalancerIP` field to your yaml manifest, as shown in the last line here:


    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
    name: myloadbalancer
    spec:
    type: LoadBalancer
    ports:
    - port: 8000
        name: http
        targetPort: 8000
    selector:
        app: mydeployment
    loadBalancerIP: 51.159.24.7
    ```

For full details and further examples of how to use flexible IPs with your Kubernetes Load Balancer, see our [dedicated documentation](/containers/kubernetes/api-cli/managing-load-balancer-ips).

## Defining your Load Balancer's configuration via annotations

Your Load Balancer will be created with a default configuration, unless you define configuration parameters via **annotations**. 

With annotations you can configure parameters such as the [balancing method](/network/load-balancer/concepts/#balancing-methods), [backend protection settings](/network/load-balancer/concepts/#backend-protection) and more. See the full list of available annotations [here](https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-annotations.md) as part of the Scaleway Cloud Controller Manager documentation.

<Message type="important">
Do **not** try to modify the configuration of your cluster's Load Balancer via the Scaleway console, the API, or any other devtools. Any modifications made this way will be overwritten by the cluster's CCM. You should **always** use annotations as described below to configure your cluster's Load Balancer.
</Message>

### Adding annotations when creating your Load Balancer

Add annotations to the `metadata` section of your LoadBalancer Service's yaml manifest as shown below. In this example we include two annotations, but you can include as many as you need.

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: myloadbalancer
      annotations:
        service.beta.kubernetes.io/scw-loadbalancer-forward-port-algorithm: "leastconn"
        service.beta.kubernetes.io/scw-loadbalancer-health-check-delay: "10s"
    spec:
      type: LoadBalancer
      ports:
      - port: 8000
        name: http
        targetPort: 8000
      selector:
        app: mydeployment
    ```

You can then create your Load Balancer with the `kubectl create -f <name-of-manifest-file>.yaml` command. 

When you examine your Load Balancer's backend configuration and health check information in the Scaleway console, you will see that the balancing method (aka forward port algorithm) and health check interval (aka health check delay) of its backend reflect the values set in the annotations.

### Modifying your Load Balancer's configuration via annotations after creation

To modify your Load Balancer's configuration with annotations after creation, you can use the `kubectl patch` command. This updates the Load Balancer according to the arguments given.

In this example, we create the following file to hold our patch, and call it `annotations-patch.yaml`:

```yaml
metadata:
  annotations:
    service.beta.kubernetes.io/scw-loadbalancer-forward-port-algorithm: "first"
    service.beta.kubernetes.io/scw-loadbalancer-health-check-timeout: "30s"
```

You can then tell the CCM to put this patch into effect with the following command:

```
kubectl patch svc myloadbalancer --type merge --patch-file annotations-patch.yaml
```

When you examine your Load Balancer's backend configuration and health check information in the Scaleway console, you will see that the balancing method (aka forward port algorithm) and health check timeout of its backend reflect the values set in the patched annotations.

<Navigation title="See Also">
  <PreviousButton to="/network/load-balancer/how-to/create-manage-routes/">How to create and manage routes</PreviousButton>
  <NextButton to="/network/load-balancer/how-to/set-up-s3-failover/">How to set up an S3 failover</NextButton>
</Navigation>

